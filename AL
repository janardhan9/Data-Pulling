
#config.py

import os
from datetime import datetime

# Project Configuration
PROJECT_NAME = "Healthcare Bills Dataset Extraction"
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# Healthcare Keywords
KEYWORDS = [
    'Prior authorization',
    'Utilization review',
    'Utilization management',
    'Medical necessity review',
    'Prompt pay',
    'Prompt payment',
    'Clean claims',
    'Clean claim',
    'Coordination of benefits',
    'Artificial intelligence',
    'Clinical decision support',
    'Automated decision making',
    'Automate decision support'
]

# Target Years
TARGET_YEARS = [2025, 2026]

# Directory Configuration
DATASETS_DIR = "datasets"
DATA_DIR = "data"
LOGS_DIR = "logs"
OUTPUT_FILE = "data/healthcare_bills_output.xlsx"
LOG_FILE = "logs/extraction.log"

# Dataset Processing Settings
MAX_DATASETS_PARALLEL = 4
DATASET_CACHE_SIZE = 1000
PARALLEL_PROCESSING = True

# Status Code Mapping
STATUS_MAPPING = {
    1: "Introduced",
    2: "Engrossed", 
    3: "Enrolled",
    4: "Passed"
}

# State Mapping
STATE_MAPPING = {
    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas',
    'CA': 'California', 'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware',
    'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho',
    'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas',
    'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',
    'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi',
    'MO': 'Missouri', 'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada',
    'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NY': 'New York',
    'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma',
    'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',
    'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah',
    'VT': 'Vermont', 'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia',
    'WI': 'Wisconsin', 'WY': 'Wyoming', 'DC': 'District of Columbia', 'US': 'United States'
}

# Logging Configuration
LOG_LEVEL = "INFO"



#Datasetmanager

import os
import json
import requests
import logging
from datetime import datetime, timedelta
from pathlib import Path
from config import *

class DatasetManager:
    def __init__(self, data_dir=DATASETS_DIR):
        """Initialize dataset manager"""
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        self.setup_logging()
        
    def setup_logging(self):
        """Setup logging for dataset operations"""
        os.makedirs(LOGS_DIR, exist_ok=True)
        logging.basicConfig(
            level=getattr(logging, LOG_LEVEL),
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(LOG_FILE),
                logging.StreamHandler()
            ]
        )
        
    def get_available_datasets(self):
        """List all downloaded datasets"""
        datasets = list(self.data_dir.glob("*-legiscan.json"))
        logging.info(f"Found {len(datasets)} datasets in {self.data_dir}")
        return datasets
    
    def check_dataset_exists(self, target_date):
        """Check if dataset for specific date already exists"""
        dataset_filename = f"{target_date}-legiscan.json"
        dataset_path = self.data_dir / dataset_filename
        return dataset_path.exists()
    
    def download_dataset_info(self):
        """Get information about available datasets from LegiScan"""
        try:
            # LegiScan datasets page
            info_url = "https://legiscan.com/datasets"
            print(f"ðŸ“Š LegiScan datasets information:")
            print(f"   Visit: {info_url}")
            print(f"   Weekly datasets are available for download")
            print(f"   Format: YYYY-MM-DD-legiscan.json")
            print(f"   Updated: Every Sunday")
            return True
        except Exception as e:
            logging.error(f"Failed to get dataset info: {e}")
            return False
    
    def download_weekly_dataset(self, target_date):
        """Download LegiScan weekly dataset for specific date"""
        dataset_filename = f"{target_date}-legiscan.json"
        dataset_path = self.data_dir / dataset_filename
        
        if dataset_path.exists():
            print(f"âœ… Dataset {dataset_filename} already exists")
            return dataset_path
            
        print(f"ðŸ“¥ Downloading dataset for {target_date}...")
        print(f"   Note: This is a placeholder - you'll need to manually download")
        print(f"   from https://legiscan.com/datasets and save as {dataset_filename}")
        
        # For now, create a placeholder file structure
        # In real implementation, you would download from LegiScan
        return dataset_path
    
    def validate_dataset(self, dataset_path):
        """Validate downloaded dataset format"""
        try:
            with open(dataset_path, 'r') as f:
                data = json.load(f)
            
            # Basic validation
            if not isinstance(data, dict):
                return False
                
            print(f"âœ… Dataset {dataset_path.name} is valid")
            return True
            
        except Exception as e:
            logging.error(f"Dataset validation failed: {e}")
            return False
    
    def get_dataset_summary(self, dataset_path):
        """Get summary information about a dataset"""
        try:
            with open(dataset_path, 'r') as f:
                data = json.load(f)
            
            # Extract summary info
            summary = {
                'file': dataset_path.name,
                'size': dataset_path.stat().st_size,
                'date': dataset_path.stat().st_mtime
            }
            
            return summary
            
        except Exception as e:
            logging.error(f"Failed to get dataset summary: {e}")
            return None

# Test the dataset manager
if __name__ == "__main__":
    print("=" * 60)
    print("HEALTHCARE BILLS DATASET MANAGER - TESTING")
    print("=" * 60)
    
    # Initialize manager
    manager = DatasetManager()
    
    # Check current datasets
    datasets = manager.get_available_datasets()
    print(f"Current datasets: {len(datasets)}")
    
    # Show dataset info
    manager.download_dataset_info()
    
    print("\nDataset manager setup complete!")
    print("Ready for Step 2: Dataset Download and Processing")
